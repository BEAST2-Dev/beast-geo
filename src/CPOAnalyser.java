


import java.util.ArrayList;
import java.util.List;

import beast.app.util.Application;
import beast.app.util.LogFile;
import beast.app.util.TreeFile;
import beast.app.util.XMLFile;
import beast.core.BEASTInterface;
import beast.core.Description;
import beast.core.Distribution;
import beast.core.Input;
import beast.core.MCMC;
import beast.core.Param;
import beast.core.Runnable;
import beast.core.State;
import beast.core.StateNode;
import beast.core.parameter.Parameter;
import beast.core.util.CompoundDistribution;
import beast.core.util.Log;
import beast.evolution.branchratemodel.*;
import beast.evolution.likelihood.GenericTreeLikelihood;
import beast.evolution.likelihood.TreeLikelihood;
import beast.evolution.tree.Node;
import beast.evolution.tree.Tree;
import beast.util.LogAnalyser;
import beast.util.Randomizer;
import beast.util.TreeParser;
import beast.util.XMLParser;
import sphericalGeo.util.treeset.MemoryFriendlyTreeSet;
import sphericalGeo.util.treeset.TreeSet;

@Description("Calculate Conditional Predictive Ordinates (CPO), which is a leave one out cross validation measure of fit "
		+ "as described in Lewis et al, Sys Bio, 2014, but adds bootstrap variance estimate as well.")	
// allows multiple partitions
// limitations: assumes a single tree (so does not work with *BEAST)
// not sure how to deal with continuous traits (e.g. geography)
public class CPOAnalyser extends Runnable {
	final public Input<XMLFile> xmlFileInput = new Input<>("xmlFile","input file containing model in BEAST XML. Expects an XML file with posterior CompoundDistribution containing a likelihood CompoundDistribution, as usually generated by BEAUti.");
	final public Input<LogFile> traceFileInput = new Input<>("logFile","input file containing trace log");
	final public Input<TreeFile> treeFileInput = new Input<>("treeFile","input file containing tree log");
	public Input<Integer> burninInput = new Input<>("burnin", "percentage of the log file to disregard as burn-in (default 10)" , 10);
	public Input<Integer> bootstrapLengthInput = new Input<>("bootstrapLength", "number of bootstrap samples used to calculate variance in CPO estimate" , 1000);

	@Override
	public void initAndValidate() {
	}

	@SuppressWarnings({ "unchecked", "rawtypes" })
	@Override
	public void run() throws Exception {
		System.setProperty("java.only", "true");
		
		// collect data
		if (burninInput.get() < 0 || burninInput.get() > 100) {
			throw new IllegalArgumentException("burnin is a percentage and should not be less than 0 or larger than 100");
		}
		LogAnalyser tracelog = new LogAnalyser(traceFileInput.get().getAbsolutePath(), burninInput.get());
		
		TreeSet treeSet = new MemoryFriendlyTreeSet(treeFileInput.get().getPath(), burninInput.get());		
    	treeSet.reset();

		XMLParser parser = new XMLParser();
		MCMC mcmc = null;
		try {
			mcmc = (MCMC) parser.parseFile(xmlFileInput.get());
			mcmc.robustlyCalcPosterior(mcmc.posteriorInput.get());
		}  catch (ClassCastException e) {
			throw new IllegalArgumentException("The XML file does not seem to contain an MCMC analysis");
		}

		// sanity check
    	if (treeSet.size() != tracelog.getTrace(0).length) {
    		throw new IllegalArgumentException("Trace and log files appear to be sampled with different frequencies (cannot hanlde that yet)");
    	}
    	
    	// reserve memory for site probabilities
    	CompoundDistribution likelihood = getLikelihood(mcmc); 
    	int patternCount = 0;
    	for (Distribution d : likelihood.pDistributions.get()) {
    		if (d instanceof GenericTreeLikelihood) {
    			patternCount += ((GenericTreeLikelihood) d).dataInput.get().getPatternCount();
    		}
    	}
    	
    	double [][] patterLogProbs = new double[patternCount][treeSet.size()];
    	int [] weights = new int[patternCount];
    	int k = 0;
    	for (Distribution d : likelihood.pDistributions.get()) {
    		if (d instanceof GenericTreeLikelihood) {
    			int [] currentWeights = ((GenericTreeLikelihood) d).dataInput.get().getWeights();
    			System.arraycopy(currentWeights, 0, weights, k, currentWeights.length);
    			k += currentWeights.length;
    		}
    	}

    	// process State
    	State state = mcmc.startStateInput.get();
    	List<StateNode> stateNodes = state.stateNodeInput.get();
    	List<Object> values = new ArrayList<>();
    	List<String> labels = tracelog.getLabels();
    	Tree tree = null;
    	for (int i = 0; i < stateNodes.size(); i++) {
    		StateNode stateNode = stateNodes.get(i);
    		String id = stateNode.getID();
    		String shortid = id.contains(".") ? id.substring(0, id.lastIndexOf('.')): id;
    		if (stateNode instanceof Parameter<?> && ((Parameter<?>) stateNode).getDimension() > 1) {
    			Parameter<?> p = ((Parameter<?>) stateNode);
    			id += ".1";
    			int index = labels.indexOf(id);
    			if (index < 0) {
        			shortid += ".1";
    				index = labels.indexOf(shortid);
    			}
    			if (index >= 0) {
    				Double [][] _values = new Double[p.getDimension()][];
    				for (int j = 0; j < p.getDimension(); j++) {
    					Double [] v = tracelog.getTrace(1 + index + j);
    					_values[j] = v;
    				}
    				values.add(_values);
    			} else {
    				Log.warning.println("Did not find " + id + " in log.");
    				values.add(null);
    			}
    		} else if (stateNodes.get(i) instanceof Tree) {
    			tree = (Tree) stateNodes.get(i);
    			values.add(null);
    		} else {
    			int index = labels.indexOf(id);
    			if (index < 0) {
    				index = labels.indexOf(shortid);
    			}
    			if (index >= 0) {
    				Double [] v = tracelog.getTrace(index + 1);
    				values.add(v);
    			} else {
    				Log.warning.println("Did not find " + id + " in log.");
    				values.add(null);
    			}
    		}
    	}
    	
    	setUpBranchRateModel(likelihood);
    	    	
		Log.warning.println("Calculating total CPO");
    	Log.warning.println("|---------|---------|---------|---------|---------|---------|---------|---------|");
		double lastLikelihood = 0;
    	k = 0;
		int reported = 0;
		treeSet.reset();
    	while (treeSet.hasNext()) {
			// set up the state
    		for (int i = 0; i < stateNodes.size(); i++) {
    			if (values.get(i) != null) {
    				Object o = values.get(i);
					StateNode stateNode = stateNodes.get(i);
    				if (o instanceof Double[]) {
    					double value = ((Double[])o)[k];
						((Parameter)stateNode).setValue(value);
    				} else {
    					Double [][] _values = (Double[][]) o;
    					for (int j = 0; j < _values.length; j++) {
    						((Parameter)stateNode).setValue(j, _values[j][k]);
    					}
    				}
    			}
    		}
			Tree currentTree = treeSet.next();
			//TreeParser p = new TreeParser(tree.getTaxonset().asStringList(), newick, 0, false);
			tree.assignFrom(currentTree);

			// calc likelihood
			mcmc.robustlyCalcPosterior(mcmc.posteriorInput.get());
			// grab site probabilities from treelikelihoods
			int i = 0;
	    	for (Distribution d : likelihood.pDistributions.get()) {
	    		if (d instanceof GenericTreeLikelihood) {
	    			TreeLikelihood tl = (TreeLikelihood) d;
	    			lastLikelihood  = tl.getCurrentLogP();
	    			double [] pll = tl.getPatternLogLikelihoods();
	    			for (int j = 0; j < pll.length; j++) {
	    				patterLogProbs[i++][k] = pll[j];
	    			}
	    		}
	    	}
					
			while (reported - k < 0) {
				Log.warning.print("*");
				reported += 1 + treeSet.size() / 86;
			}
			k++;		
		}

    	// precalc total log pseudomarginal likelihood (LPML) from siteProbs array
  		// Part of Equation (14) in Lewis et al 2014
    	double [] minLogP = new double[patternCount];
		for (int i = 0; i < patternCount; i++) {
			double min = patterLogProbs[i][0];
			for (k = 0; k < treeSet.size(); k++) {
    			min = Math.min(min, patterLogProbs[i][k]);
    		}
    		minLogP[i] = min;
    	}
    	
		int [] order = new int[treeSet.size()];
		for (int i = 0; i < order.length; i++) {
			order[i] = i;
		}
		double LPML = calcLPML(order, minLogP, patterLogProbs, weights);
		Log.info.println("\nSanity check: make sure the last likelihood in the log file is: " + lastLikelihood);

  		Log.info("\nlog pseudomarginal likelihood (LPML) = " + LPML);
    	
    	Log.warning.println("Calculating variance of CPO");
    	Log.warning.println("|---------|---------|---------|---------|---------|---------|---------|---------|");
    	int siteCount = 0;
    	for (int d : weights) {
    		siteCount += d;
    	}
    	// maps site index to pattern index
    	int [] siteMap = new int[siteCount];
    	k = 0;
    	for (int i = 0; i < patternCount; i++) {
    		for (int j = 0; j < weights[i]; j++) {
    			siteMap[k++] = i;
    		}
    	}
    	reported = 0;
    	int replicates = bootstrapLengthInput.get();
    	k = 0;
    	double [] LPMLs = new double[replicates];
    	while (k < replicates) {
        	// calc CPO from subsample of siteProbs array
			order = Randomizer.sampleIndicesWithReplacement(treeSet.size());
    		LPMLs[k] = calcLPML(order, minLogP, patterLogProbs, weights);
    		
			while (reported - k < 0) {
				Log.warning.print("*");
				reported += 1 + replicates / 80;
			}
			k++;		
		}
    	
        // Summarise 
    	double mean = 0;
        for (int i = 0; i < replicates; i++) {
            mean += LPMLs[i];
        }
        mean /= replicates;
    	
        double var = 0;
        for (int i = 0; i < replicates; i++) {
            var += (LPMLs[i] - mean) *
                    (LPMLs[i] - mean);
        }
        var /= (replicates - 1.0);
        double standardDeviation = Math.sqrt(var);
        Log.info("\nmean = " + mean + ", standardDeviation = " + standardDeviation);

	}

	private void setUpBranchRateModel(CompoundDistribution likelihood) {
    	// set up branch rate model to pick up rates from Tree metadata
		for (Distribution d : likelihood.pDistributions.get()) {
			if (d instanceof GenericTreeLikelihood) {
				GenericTreeLikelihood tl = (GenericTreeLikelihood) d;
				BEASTInterface clock = (BEASTInterface) tl.branchRateModelInput.get();
				if (hasInput(clock, "tree")) {
					Input<?> input = clock.getInput("tree");
					if (input != null) {
						Object o = input.get();
						if (o != null &&  o instanceof Tree) {
							Tree tree = (Tree) o;
							RateByMetaData newClock = new RateByMetaData(tree);
							newClock.meanRateInput.setValue(clock.getInput("clock.rate").get(), newClock);
							tl.branchRateModelInput.setValue(newClock, tl);
							tl.initAndValidate();
						}
					}
				}
			}
		}
	}

	private boolean hasInput(BEASTInterface clock, String name) {
		for (Input<?> input : clock.listInputs()) {
			if (input.getName().equals(name)) {
				return true;
			}
		}
		return false;
	}

	class RateByMetaData extends BranchRateModel.Base {

		RateByMetaData(@Param(name="tree",description="beast tree with metadata containing rates")Tree tree) {
			this.tree = tree;
		}
		
		@Override
		public void initAndValidate() {
		}

		@Override
		public double getRateForBranch(Node node) {
			Node src = tree.getNode(node.getNr());
			Object o = src.getMetaData("rate");
			if (o == null) {
				return meanRateInput.get().getValue();
			}
			if (o instanceof Double) {
				return (Double) o;
			}
			String value = o.toString();
			double rate = Double.parseDouble(value);
			return rate;
		}

		Tree tree;
		public Tree getTree() {return tree;}
		public void setTree(Tree tree) {this.tree = tree;}
	}
	
	private double calcLPML(int [] order, double[] minLogP, double[][] patterLogProbs, int[] patternWeights) {
		int patternCount = patterLogProbs.length;
		int treeSetSize = patterLogProbs[0].length;
  		// Equation (14) in Lewis et al 2014
    	double [] CPOi = new double[patternCount];
  		for (int i = 0; i < patternCount; i++) {
    		double CPOi_ = Math.log(treeSetSize) + minLogP[i];
    		double sum = 0;
    		double [] p = patterLogProbs[i];
        	for (int k : order) {
        		sum += Math.exp(minLogP[i] - p[k]);
    		}
        	CPOi_ -= Math.log(sum);
    		CPOi[i] = CPOi_;
    	}
    	
  		// Equation (15) in Lewis et al 2014
  		double LPML = 0;
  		for (int i = 0; i < patternCount; i++) {
  			LPML += CPOi[i] * patternWeights[i];
  		}
		return LPML;
	}

	private CompoundDistribution getLikelihood(MCMC mcmc) {
		if (!(mcmc.posteriorInput.get() instanceof CompoundDistribution)) {
			throw new IllegalArgumentException("The XML file does not seem to contain an MCMC analysis with posterior CompoundDistribution");
		}
		CompoundDistribution posterior = (CompoundDistribution) mcmc.posteriorInput.get();
		for (Distribution d : posterior.pDistributions.get()) {
			if (d.getID().equals("likelihood")) {
				if (!(d instanceof CompoundDistribution)) {
					throw new IllegalArgumentException("The XML file does not seem to contain an MCMC analysis with likelihood CompoundDistribution");
				}
				return (CompoundDistribution) d;
			}
		}
		throw new IllegalArgumentException("The XML file does not seem to contain an MCMC analysis with a 'likelihood' in the posterior");
	} // getLikelihood

	public static void main(String[] args) throws Exception {
		new Application(new CPOAnalyser(), "CPOAnalyser", args);
	}
}



